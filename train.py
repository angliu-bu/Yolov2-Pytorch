import argparse
import os
import numpy as np
from util import parse_annotation
#from frontend import YOLO
import json

os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0"

argparser = argparse.ArgumentParser(
    description='Train and validate YOLO_v2 model on COCO 2014 dataset')

argparser.add_argument(
    '-c',
    '--conf',
    help='path to configuration file')

def _main_(args):
    config_path = args.conf

    with open(config_path) as config_buffer:    
        config = json.loads(config_buffer.read())

    ###############################
    #   Parse the annotations 
    ###############################

    # parse annotations of the training set
    # train_imgs is a list of dictionary with the following keys and contents: 
    #     object   : a list of objects in the image, each object is a dictionary with object name, box coordinates (xmin, xmax, ymin, ymax)
    #     filename : complete path of the image  
    #     width    : original pixel width
    #     height   : original pixel height
    # train_labels contains the statistics of the count of each type of object 
#    train_imgs, train_labels = parse_annotation(config['train']['train_annot_folder'], 
#                                                config['train']['train_image_folder'], 
#                                                config['model']['labels'])
 
    # split the training set into 80% training and 20% validation
#    if os.path.exists(config['valid']['valid_annot_folder']):
#        valid_imgs, valid_labels = parse_annotation(config['valid']['valid_annot_folder'], 
#                                                    config['valid']['valid_image_folder'], 
#                                                    config['model']['labels'])
#    else:
#        train_valid_split = int(0.8*len(train_imgs))
#        np.random.shuffle(train_imgs)
#        valid_imgs = train_imgs[train_valid_split:]
#        train_imgs = train_imgs[:train_valid_split]

    # parse annotations of the testing set
    test_imgs, test_labels = parse_annotation(config['test']['test_annot_folder'],
                                              config['test']['test_image_folder'],
                                              config['model']['labels'])
    
    print(len(train_imgs), len(valid_imgs), len(test_imgs))

    if len(config['model']['labels']) > 0:
        overlap_labels = set(config['model']['labels']).intersection(set(train_labels.keys()))

        print('Seen labels:\t', train_labels)
        print('Given labels:\t', config['model']['labels'])
        print('Overlap labels:\t', overlap_labels)           

        if len(overlap_labels) < len(config['model']['labels']):
            print('Some labels have no annotations! Please revise the list of labels in the config.json file!')
            return
    else:
        print('No labels are provided. Train on all seen labels.')
        config['model']['labels'] = train_labels.keys()





if __name__ == '__main__':
    args = argparser.parse_args()
    _main_(args)

